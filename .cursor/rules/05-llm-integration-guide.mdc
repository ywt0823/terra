---
description: 
globs: 
alwaysApply: true
---
# LLM 集成指南

本文档提供在 Terra Framework 中集成和使用大语言模型(LLM)的指南。

## 支持的模型

Terra Framework 支持以下 LLM 供应商和模型：

- **OpenAI**:GPT-3.5-Turbo、GPT-4 等
- **Anthropic Claude**:Claude 3 Haiku、Claude 3 Sonnet 等
- **百度文心一言**:ERNIE-Bot 等
- **阿里通义千问**:Qwen 系列模型
- **Ollama**：本地部署的开源模型

## 基本用法

### 1. 配置模型供应商

在 `application.yml` 中配置：

```yaml
terra:
  nova:
    model:
      default-provider: openai  # 默认供应商
      providers:
        openai:
          api-key: ${OPENAI_API_KEY}
          base-url: https://api.openai.com/v1
          models:
            - name: gpt-3.5-turbo
              type: CHAT
              max-tokens: 4096
        claude:
          api-key: ${ANTHROPIC_API_KEY}
          models:
            - name: claude-3-haiku
              type: CHAT
              max-tokens: 4096
```

### 2. 使用基础 AI 服务

通过依赖注入使用 `AIService` 接口：

```java
@Autowired
private AIService aiService;

// 简单对话
String response = aiService.chat("你好，请介绍一下自己");

// 带上下文的对话
List<Message> messages = new ArrayList<>();
messages.add(new Message(MessageRole.SYSTEM, "你是一个专业的金融顾问"));
messages.add(new Message(MessageRole.USER, "什么是ETF?"));
String response = aiService.chat(messages);
```

### 3. 使用增强型 AI 服务

增强型服务提供重试、缓存等高级功能：

```java
@Autowired
private EnhancedAIService enhancedAIService;

ModelResponse response = enhancedAIService.generateWithRetryAndCache(
    ModelRequest.builder()
        .messages(List.of(new Message(MessageRole.USER, "分析以下数据并提取关键信息")))
        .modelName("gpt-3.5-turbo")
        .temperature(0.7)
        .maxTokens(1000)
        .build()
);
```

### 4. 使用模型混合功能

混合多个模型的结果：

```java
@Autowired
private BlenderService blenderService;

// 使用两个模型混合回答，并采用质量优先的合并策略
String blendedResponse = blenderService.blend(
    "请解释量子计算的基本原理",
    List.of("gpt-3.5-turbo", "claude-3-haiku"),
    MergeStrategy.BEST_QUALITY
);

// 更复杂的混合配置
BlendRequest request = BlendRequest.builder()
    .prompt("分析这段代码的安全漏洞")
    .models(Map.of(
        "gpt-4", 0.7,  // 权重为0.7
        "claude-3-sonnet", 0.3  // 权重为0.3
    ))
    .strategy(MergeStrategy.WEIGHTED_AVERAGE)
    .build();

String result = blenderService.blend(request);
```

## 自定义模型适配器

实现 `ModelAdapter` 接口来支持新的 LLM 供应商：

```java
@Component
public class CustomModelAdapter implements ModelAdapter {
    
    @Override
    public String getProviderName() {
        return "custom-provider";
    }
    
    @Override
    public ModelResponse generate(ModelRequest request) {
        // 实现与自定义 LLM API 的交互
    }
    
    @Override
    public boolean supportsModel(String modelName) {
        return modelName.startsWith("custom-");
    }
}
```

## 最佳实践

1. **选择合适的模型**：对于简单任务使用轻量模型，复杂任务使用高级模型
2. **设置合理的温度**：创意性任务使用较高温度(0.7-0.9)，事实性任务使用较低温度(0.1-0.3)
3. **利用系统提示词**：使用明确的系统提示词定义模型行为
4. **启用缓存**：对于相同或相似的请求，启用缓存以提高性能
5. **模型混合**：关键决策使用多模型混合以获取更可靠的结果
